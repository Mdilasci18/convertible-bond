{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e38d358",
   "metadata": {},
   "source": [
    "### Factors based on Machine Learning Model\n",
    "This notebook created factors using ML algo to improve the predictability of `next_ovnt_ret`.\n",
    "\n",
    "Based on the results shown in `Data Analysis.ipynb`, a **Classification task** is designed specifically for this work instead of Prediction task on convertible bond return.\n",
    "\n",
    "The machine learning models used in this work includes:\n",
    "+ KNN\n",
    "+ Random Forest\n",
    "+ XGBoost\n",
    "\n",
    "Finally, specific evaluation metrics are designed to show the pros and cons of each machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83701878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import import_ipynb\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm, trange\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39812cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../../../export/scratch/for_yifan/research/'\n",
    "\n",
    "# data loading\n",
    "model_data = pd.read_csv(os.path.join(data_path, 'ml_model_data.csv'), index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a107bd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>next_ovnt_ret</th>\n",
       "      <th>class</th>\n",
       "      <th>weight</th>\n",
       "      <th>date</th>\n",
       "      <th>bond_ticker</th>\n",
       "      <th>stock_ticker</th>\n",
       "      <th>ovnt_ret</th>\n",
       "      <th>intra_ret</th>\n",
       "      <th>premium_open</th>\n",
       "      <th>premium_close</th>\n",
       "      <th>neg_premium</th>\n",
       "      <th>bond_weight</th>\n",
       "      <th>stock_weight</th>\n",
       "      <th>stock_ovnt_ret</th>\n",
       "      <th>stock_intra_ret</th>\n",
       "      <th>stock_ret</th>\n",
       "      <th>top1500</th>\n",
       "      <th>CSI300</th>\n",
       "      <th>CSI800</th>\n",
       "      <th>ret</th>\n",
       "      <th>abs_ret</th>\n",
       "      <th>abs_ovnt_ret</th>\n",
       "      <th>abs_intra_ret</th>\n",
       "      <th>abs_stock_ret</th>\n",
       "      <th>up</th>\n",
       "      <th>up_bool</th>\n",
       "      <th>ovnt_ret3</th>\n",
       "      <th>ret3</th>\n",
       "      <th>abs_ret3</th>\n",
       "      <th>abs_intra_ret3</th>\n",
       "      <th>stock_ovnt_ret3</th>\n",
       "      <th>premium_close3</th>\n",
       "      <th>premium_open3</th>\n",
       "      <th>spread3</th>\n",
       "      <th>ovnt_ret5</th>\n",
       "      <th>ret5</th>\n",
       "      <th>abs_ret5</th>\n",
       "      <th>abs_intra_ret5</th>\n",
       "      <th>stock_ovnt_ret5</th>\n",
       "      <th>premium_close5</th>\n",
       "      <th>premium_open5</th>\n",
       "      <th>spread5</th>\n",
       "      <th>ovnt_ret10</th>\n",
       "      <th>ret10</th>\n",
       "      <th>abs_ret10</th>\n",
       "      <th>abs_intra_ret10</th>\n",
       "      <th>stock_ovnt_ret10</th>\n",
       "      <th>premium_close10</th>\n",
       "      <th>premium_open10</th>\n",
       "      <th>spread10</th>\n",
       "      <th>ovnt_ret30</th>\n",
       "      <th>ret30</th>\n",
       "      <th>abs_ret30</th>\n",
       "      <th>abs_intra_ret30</th>\n",
       "      <th>stock_ovnt_ret30</th>\n",
       "      <th>premium_close30</th>\n",
       "      <th>premium_open30</th>\n",
       "      <th>spread30</th>\n",
       "      <th>ovnt_ret60</th>\n",
       "      <th>ret60</th>\n",
       "      <th>abs_ret60</th>\n",
       "      <th>abs_intra_ret60</th>\n",
       "      <th>stock_ovnt_ret60</th>\n",
       "      <th>premium_close60</th>\n",
       "      <th>premium_open60</th>\n",
       "      <th>spread60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0052</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>20170104</td>\n",
       "      <td>110030.SH</td>\n",
       "      <td>600185.SH</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.4172</td>\n",
       "      <td>0.4032</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0.4032</td>\n",
       "      <td>0.4172</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0.4032</td>\n",
       "      <td>0.4172</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0.4032</td>\n",
       "      <td>0.4172</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0.4032</td>\n",
       "      <td>0.4172</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0.4032</td>\n",
       "      <td>0.4172</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>20170104</td>\n",
       "      <td>110031.SH</td>\n",
       "      <td>600271.SH</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>1.2868</td>\n",
       "      <td>1.2911</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1101</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>-0.0015</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>1.2911</td>\n",
       "      <td>1.2868</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>1.2911</td>\n",
       "      <td>1.2868</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>1.2911</td>\n",
       "      <td>1.2868</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>1.2911</td>\n",
       "      <td>1.2868</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>1.2911</td>\n",
       "      <td>1.2868</td>\n",
       "      <td>0.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>20170104</td>\n",
       "      <td>110032.SH</td>\n",
       "      <td>600031.SH</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.3356</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.3356</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.3356</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.3356</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.3356</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.3356</td>\n",
       "      <td>-0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.0034</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>20170104</td>\n",
       "      <td>110033.SH</td>\n",
       "      <td>600755.SH</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.2274</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.1409</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.2274</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.2274</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.2274</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.2274</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.2274</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0075</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>20170104</td>\n",
       "      <td>110034.SH</td>\n",
       "      <td>600998.SH</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.1109</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>-0.0108</td>\n",
       "      <td>-0.0062</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.1109</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.1109</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.1109</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.1109</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.1109</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>-0.0012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   next_ovnt_ret  class  weight      date bond_ticker stock_ticker  ovnt_ret  \\\n",
       "0         0.0052      1  0.0042  20170104   110030.SH    600185.SH   -0.0004   \n",
       "1         0.0002      0  0.0008  20170104   110031.SH    600271.SH    0.0027   \n",
       "2         0.0000      0  0.0010  20170104   110032.SH    600031.SH   -0.0018   \n",
       "3        -0.0034      0  0.0044  20170104   110033.SH    600755.SH    0.0000   \n",
       "4         0.0075      1  0.0065  20170104   110034.SH    600998.SH   -0.0002   \n",
       "\n",
       "   intra_ret  premium_open  premium_close  neg_premium  bond_weight  \\\n",
       "0     0.0020        0.4172         0.4032        False       0.0065   \n",
       "1    -0.0016        1.2868         1.2911        False       0.1101   \n",
       "2     0.0038        0.3356         0.3257        False       0.1056   \n",
       "3     0.0074        0.2274         0.2233        False       0.0528   \n",
       "4     0.0123        0.0855         0.1109        False       0.0425   \n",
       "\n",
       "   stock_weight  stock_ovnt_ret  stock_intra_ret  stock_ret  top1500  CSI300  \\\n",
       "0        0.0195         -0.0017           0.0120     0.0103    False   False   \n",
       "1        0.1049          0.0020          -0.0034    -0.0015    False    True   \n",
       "2        0.0771         -0.0016           0.0112     0.0096    False    True   \n",
       "3        0.1409          0.0000           0.0107     0.0107     True   False   \n",
       "4        0.0399          0.0047          -0.0108    -0.0062    False   False   \n",
       "\n",
       "   CSI800    ret  abs_ret  abs_ovnt_ret  abs_intra_ret  abs_stock_ret  up  \\\n",
       "0   False 0.0017   0.0017        0.0004         0.0020         0.0103   0   \n",
       "1    True 0.0011   0.0011        0.0027         0.0016         0.0015   0   \n",
       "2    True 0.0020   0.0020        0.0018         0.0038         0.0096   0   \n",
       "3    True 0.0074   0.0074        0.0000         0.0074         0.0107   0   \n",
       "4   False 0.0121   0.0121        0.0002         0.0123         0.0062   0   \n",
       "\n",
       "   up_bool  ovnt_ret3   ret3  abs_ret3  abs_intra_ret3  stock_ovnt_ret3  \\\n",
       "0    False    -0.0004 0.0017    0.0017          0.0020          -0.0017   \n",
       "1    False     0.0027 0.0011    0.0011          0.0016           0.0020   \n",
       "2    False    -0.0018 0.0020    0.0020          0.0038          -0.0016   \n",
       "3    False     0.0000 0.0074    0.0074          0.0074           0.0000   \n",
       "4    False    -0.0002 0.0121    0.0121          0.0123           0.0047   \n",
       "\n",
       "   premium_close3  premium_open3  spread3  ovnt_ret5   ret5  abs_ret5  \\\n",
       "0          0.4032         0.4172   0.0001    -0.0004 0.0017    0.0017   \n",
       "1          1.2911         1.2868   0.0021     0.0027 0.0011    0.0011   \n",
       "2          0.3257         0.3356  -0.0014    -0.0018 0.0020    0.0020   \n",
       "3          0.2233         0.2274   0.0000     0.0000 0.0074    0.0074   \n",
       "4          0.1109         0.0855  -0.0014    -0.0002 0.0121    0.0121   \n",
       "\n",
       "   abs_intra_ret5  stock_ovnt_ret5  premium_close5  premium_open5  spread5  \\\n",
       "0          0.0020          -0.0017          0.4032         0.4172   0.0001   \n",
       "1          0.0016           0.0020          1.2911         1.2868   0.0022   \n",
       "2          0.0038          -0.0016          0.3257         0.3356  -0.0014   \n",
       "3          0.0074           0.0000          0.2233         0.2274   0.0000   \n",
       "4          0.0123           0.0047          0.1109         0.0855  -0.0014   \n",
       "\n",
       "   ovnt_ret10  ret10  abs_ret10  abs_intra_ret10  stock_ovnt_ret10  \\\n",
       "0     -0.0004 0.0017     0.0017           0.0020           -0.0017   \n",
       "1      0.0027 0.0011     0.0011           0.0016            0.0020   \n",
       "2     -0.0018 0.0020     0.0020           0.0038           -0.0016   \n",
       "3      0.0000 0.0074     0.0074           0.0074            0.0000   \n",
       "4     -0.0002 0.0121     0.0121           0.0123            0.0047   \n",
       "\n",
       "   premium_close10  premium_open10  spread10  ovnt_ret30  ret30  abs_ret30  \\\n",
       "0           0.4032          0.4172    0.0001     -0.0004 0.0017     0.0017   \n",
       "1           1.2911          1.2868    0.0022      0.0027 0.0011     0.0011   \n",
       "2           0.3257          0.3356   -0.0014     -0.0018 0.0020     0.0020   \n",
       "3           0.2233          0.2274    0.0000      0.0000 0.0074     0.0074   \n",
       "4           0.1109          0.0855   -0.0013     -0.0002 0.0121     0.0121   \n",
       "\n",
       "   abs_intra_ret30  stock_ovnt_ret30  premium_close30  premium_open30  \\\n",
       "0           0.0020           -0.0017           0.4032          0.4172   \n",
       "1           0.0016            0.0020           1.2911          1.2868   \n",
       "2           0.0038           -0.0016           0.3257          0.3356   \n",
       "3           0.0074            0.0000           0.2233          0.2274   \n",
       "4           0.0123            0.0047           0.1109          0.0855   \n",
       "\n",
       "   spread30  ovnt_ret60  ret60  abs_ret60  abs_intra_ret60  stock_ovnt_ret60  \\\n",
       "0    0.0000     -0.0004 0.0017     0.0017           0.0020           -0.0017   \n",
       "1    0.0022      0.0027 0.0011     0.0011           0.0016            0.0020   \n",
       "2   -0.0014     -0.0018 0.0020     0.0020           0.0038           -0.0016   \n",
       "3    0.0000      0.0000 0.0074     0.0074           0.0074            0.0000   \n",
       "4   -0.0012     -0.0002 0.0121     0.0121           0.0123            0.0047   \n",
       "\n",
       "   premium_close60  premium_open60  spread60  \n",
       "0           0.4032          0.4172    0.0000  \n",
       "1           1.2911          1.2868    0.0022  \n",
       "2           0.3257          0.3356   -0.0014  \n",
       "3           0.2233          0.2274    0.0000  \n",
       "4           0.1109          0.0855   -0.0012  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data labeling\n",
    "model_data['date'] = model_data['date'].map(lambda x: str(x))\n",
    "\n",
    "thr = 0.001\n",
    "model_data['class'] = (model_data['next_ovnt_ret'] >= thr) * 1\n",
    "model_data['weight'] = (model_data['next_ovnt_ret'] - thr).abs()\n",
    "model_data = model_data[['next_ovnt_ret', 'class', 'weight'] + [col for col in model_data.columns \n",
    "                                            if col not in ['next_ovnt_ret', 'class', 'weight']]].reset_index(drop=True)\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd646d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nan check\n",
    "model_data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae48853a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    68967\n",
       "1    28194\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label distribution\n",
    "model_data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d46721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0   -0.0026\n",
       "1    0.0084\n",
       "Name: next_ovnt_ret, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class y\n",
    "model_data.groupby('class')['next_ovnt_ret'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11ec26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train = model_data[model_data['date'] <= '20191231'].copy()\n",
    "test = model_data[model_data['date'] > '20191231'].copy()\n",
    "train_X, train_y = train.iloc[:, 6:].astype('float64'),  train.iloc[:, 1].values\n",
    "test_X, test_y = test.iloc[:, 6:].astype('float64'),  test.iloc[:, 1].values\n",
    "train_weight = train['weight']\n",
    "test_weight = test['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "530c9c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelEval(para, para_name, train_pred, test_pred):\n",
    "    \"\"\"\n",
    "    evaluation metrics on classification performance from the prespective of trading\n",
    "    \"\"\"\n",
    "    train_ret = train.loc[train_pred.astype('bool'), 'next_ovnt_ret']  # next_ovnt_ret with predicted label==True\n",
    "    test_ret = test.loc[test_pred.astype('bool'), 'next_ovnt_ret']\n",
    "    \n",
    "    info = {\n",
    "        '{}'.format(para_name): para,\n",
    "        'train_sig_num': len(train_ret),     # total signal number in training set\n",
    "        'train_ret_mean': train_ret.mean(),  # average signal return in training set\n",
    "        'train_ret_total': train_ret.sum(),  # total signal return in training set\n",
    "        'train_profit_rate': (train_ret > 0.0002).sum() / len(train_ret), # winning rate of the signal in training set\n",
    "        'test_sig_num': len(test_ret),       # total signal number in testing set\n",
    "        'test_ret_mean': test_ret.mean(),    # average signal return in testing set\n",
    "        'test_ret_total': test_ret.sum(),    # total signal return in testing set\n",
    "        'test_profit_rate': (test_ret > 0.0002).sum() / len(test_ret),    # winning rate of the signal in testing set\n",
    "    }\n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "def knnEval(train_X, train_y, train, test_X, test_y, test):\n",
    "    \"\"\"\n",
    "    evalution function for KNN with different parameters\n",
    "    \"\"\"\n",
    "    neighbors = [10, 30, 50, 100]\n",
    "    eva = []\n",
    "\n",
    "    for n in tqdm(neighbors):\n",
    "        knn = KNeighborsClassifier(n_neighbors=n, weights='uniform')\n",
    "        knn.fit(train_X, train_y)\n",
    "        train_pred = knn.predict(train_X)\n",
    "        test_pred = knn.predict(test_X)\n",
    "    \n",
    "        info = modelEval(n, 'n_neighbors', train_pred, test_pred)\n",
    "        eva.append(info)\n",
    "        model_data['knn{}'.format(n)] = np.concatenate((train_pred, test_pred))\n",
    "        \n",
    "    return pd.DataFrame(eva)\n",
    "\n",
    "\n",
    "def rfEval(train_X, train_y, train, test_X, test_y, test):\n",
    "    \"\"\"\n",
    "    evalution function for Random Forest with different parameters\n",
    "    \"\"\"\n",
    "    max_depth = [5, 10, 50]\n",
    "    split = [0.002, 0.005, 0.01]\n",
    "    eva = []\n",
    "\n",
    "    for d in tqdm(max_depth):\n",
    "        for s in split:\n",
    "            rf = RandomForestClassifier(max_depth=d, min_samples_split=s, \n",
    "                                        random_state=100, oob_score=True)\n",
    "            rf.fit(train_X, train_y)\n",
    "            train_pred = rf.predict(train_X)\n",
    "            test_pred = rf.predict(test_X)\n",
    "\n",
    "            info = modelEval((d, s), 'max_depth, min_samples_split', train_pred, test_pred)\n",
    "            eva.append(info)\n",
    "            model_data['rf{}_{}'.format(d, s)] = np.concatenate((train_pred, test_pred))\n",
    "        \n",
    "    return pd.DataFrame(eva)\n",
    "\n",
    "\n",
    "def xgbEval(train_X, train_y, train, test_X, test_y, test):\n",
    "    \"\"\"\n",
    "    evalution function for XGBoost with different parameters\n",
    "    \"\"\"\n",
    "    n_estimators = [10, 20, 50]\n",
    "    gamma = [10, 20, 50]\n",
    "    eva = []\n",
    "\n",
    "    for n in tqdm(n_estimators):\n",
    "        for g in gamma:\n",
    "            xgb = XGBClassifier(n_estimators=n,\n",
    "                                gamma=g,\n",
    "                                learning_rate=0.3,\n",
    "                                min_child_weight=100,\n",
    "                                max_depth=100,\n",
    "                                alpha = 1,\n",
    "                                subsample=0.8,\n",
    "                                colsample_bytree=0.8,\n",
    "                                random_state=100,\n",
    "                                use_label_encoder=False)\n",
    "            xgb.fit(train_X, train_y, eval_metric='auc')\n",
    "            train_pred = xgb.predict(train_X)\n",
    "            test_pred = xgb.predict(test_X)\n",
    "\n",
    "            info = modelEval((n, g), 'n_estimators, gamma', train_pred, test_pred)\n",
    "            eva.append(info)\n",
    "            model_data['xgb{}_{}'.format(n, g)] = np.concatenate((train_pred, test_pred))\n",
    "\n",
    "    return pd.DataFrame(eva)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb831e7",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a2dcba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [05:15<00:00, 78.99s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>train_sig_num</th>\n",
       "      <th>train_ret_mean</th>\n",
       "      <th>train_ret_total</th>\n",
       "      <th>train_profit_rate</th>\n",
       "      <th>test_sig_num</th>\n",
       "      <th>test_ret_mean</th>\n",
       "      <th>test_ret_total</th>\n",
       "      <th>test_profit_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2929</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>13.4855</td>\n",
       "      <td>0.7139</td>\n",
       "      <td>2246</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>7.8659</td>\n",
       "      <td>0.5396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>1517</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>6.5476</td>\n",
       "      <td>0.6513</td>\n",
       "      <td>1357</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>5.8527</td>\n",
       "      <td>0.5660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>1135</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>5.0673</td>\n",
       "      <td>0.6608</td>\n",
       "      <td>989</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>4.0267</td>\n",
       "      <td>0.5763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>664</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>2.9742</td>\n",
       "      <td>0.6596</td>\n",
       "      <td>608</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2.3393</td>\n",
       "      <td>0.5592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_neighbors  train_sig_num  train_ret_mean  train_ret_total  \\\n",
       "0           10           2929          0.0046          13.4855   \n",
       "1           30           1517          0.0043           6.5476   \n",
       "2           50           1135          0.0045           5.0673   \n",
       "3          100            664          0.0045           2.9742   \n",
       "\n",
       "   train_profit_rate  test_sig_num  test_ret_mean  test_ret_total  \\\n",
       "0             0.7139          2246         0.0035          7.8659   \n",
       "1             0.6513          1357         0.0043          5.8527   \n",
       "2             0.6608           989         0.0041          4.0267   \n",
       "3             0.6596           608         0.0038          2.3393   \n",
       "\n",
       "   test_profit_rate  \n",
       "0            0.5396  \n",
       "1            0.5660  \n",
       "2            0.5763  \n",
       "3            0.5592  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnEval(train_X, train_y, train, test_X, test_y, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dae372ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:48<00:00, 56.30s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth, min_samples_split</th>\n",
       "      <th>train_sig_num</th>\n",
       "      <th>train_ret_mean</th>\n",
       "      <th>train_ret_total</th>\n",
       "      <th>train_profit_rate</th>\n",
       "      <th>test_sig_num</th>\n",
       "      <th>test_ret_mean</th>\n",
       "      <th>test_ret_total</th>\n",
       "      <th>test_profit_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(5, 0.002)</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>5.4081</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>3453</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>27.8984</td>\n",
       "      <td>0.6232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(5, 0.005)</td>\n",
       "      <td>1077</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>5.4091</td>\n",
       "      <td>0.6546</td>\n",
       "      <td>3294</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>26.1438</td>\n",
       "      <td>0.6254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(5, 0.01)</td>\n",
       "      <td>1092</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>5.4761</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>3226</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>27.1955</td>\n",
       "      <td>0.6293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10, 0.002)</td>\n",
       "      <td>1724</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>11.8770</td>\n",
       "      <td>0.7912</td>\n",
       "      <td>4194</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>30.8654</td>\n",
       "      <td>0.6273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10, 0.005)</td>\n",
       "      <td>1569</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>9.3649</td>\n",
       "      <td>0.7298</td>\n",
       "      <td>4201</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>31.4784</td>\n",
       "      <td>0.6258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(10, 0.01)</td>\n",
       "      <td>1392</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>7.5327</td>\n",
       "      <td>0.6868</td>\n",
       "      <td>3988</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>31.1778</td>\n",
       "      <td>0.6291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(50, 0.002)</td>\n",
       "      <td>2294</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>18.1102</td>\n",
       "      <td>0.8697</td>\n",
       "      <td>4608</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>33.1970</td>\n",
       "      <td>0.6233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(50, 0.005)</td>\n",
       "      <td>1689</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>10.2109</td>\n",
       "      <td>0.7501</td>\n",
       "      <td>4148</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>31.1629</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(50, 0.01)</td>\n",
       "      <td>1427</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>7.7736</td>\n",
       "      <td>0.6938</td>\n",
       "      <td>4018</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>29.8176</td>\n",
       "      <td>0.6227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  max_depth, min_samples_split  train_sig_num  train_ret_mean  \\\n",
       "0                   (5, 0.002)           1120          0.0048   \n",
       "1                   (5, 0.005)           1077          0.0050   \n",
       "2                    (5, 0.01)           1092          0.0050   \n",
       "3                  (10, 0.002)           1724          0.0069   \n",
       "4                  (10, 0.005)           1569          0.0060   \n",
       "5                   (10, 0.01)           1392          0.0054   \n",
       "6                  (50, 0.002)           2294          0.0079   \n",
       "7                  (50, 0.005)           1689          0.0060   \n",
       "8                   (50, 0.01)           1427          0.0054   \n",
       "\n",
       "   train_ret_total  train_profit_rate  test_sig_num  test_ret_mean  \\\n",
       "0           5.4081             0.6571          3453         0.0081   \n",
       "1           5.4091             0.6546          3294         0.0079   \n",
       "2           5.4761             0.6548          3226         0.0084   \n",
       "3          11.8770             0.7912          4194         0.0074   \n",
       "4           9.3649             0.7298          4201         0.0075   \n",
       "5           7.5327             0.6868          3988         0.0078   \n",
       "6          18.1102             0.8697          4608         0.0072   \n",
       "7          10.2109             0.7501          4148         0.0075   \n",
       "8           7.7736             0.6938          4018         0.0074   \n",
       "\n",
       "   test_ret_total  test_profit_rate  \n",
       "0         27.8984            0.6232  \n",
       "1         26.1438            0.6254  \n",
       "2         27.1955            0.6293  \n",
       "3         30.8654            0.6273  \n",
       "4         31.4784            0.6258  \n",
       "5         31.1778            0.6291  \n",
       "6         33.1970            0.6233  \n",
       "7         31.1629            0.6275  \n",
       "8         29.8176            0.6227  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfEval(train_X, train_y, train, test_X, test_y, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a20a3f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest feature importance visulization\n",
    "rf = RandomForestClassifier(max_depth=5, min_samples_split=0.01, \n",
    "                                        random_state=100, oob_score=True)\n",
    "rf.fit(train_X, train_y)\n",
    "\n",
    "fig = pd.DataFrame(rf.feature_importances_, index=train_X.columns, \n",
    "             columns=['importance']).sort_values(by='importance', ascending=False).iloc[:20].iloc[-1::-1].plot.barh(title='rf5_0.01 feature importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c51eb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:09<00:00,  3.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators, gamma</th>\n",
       "      <th>train_sig_num</th>\n",
       "      <th>train_ret_mean</th>\n",
       "      <th>train_ret_total</th>\n",
       "      <th>train_profit_rate</th>\n",
       "      <th>test_sig_num</th>\n",
       "      <th>test_ret_mean</th>\n",
       "      <th>test_ret_total</th>\n",
       "      <th>test_profit_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>2105</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>9.0737</td>\n",
       "      <td>0.6580</td>\n",
       "      <td>4703</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>28.9818</td>\n",
       "      <td>0.6028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10, 20)</td>\n",
       "      <td>1485</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>6.2007</td>\n",
       "      <td>0.6424</td>\n",
       "      <td>4262</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>29.3659</td>\n",
       "      <td>0.6138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10, 50)</td>\n",
       "      <td>1004</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>4.0890</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>2956</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>20.5244</td>\n",
       "      <td>0.6045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(20, 10)</td>\n",
       "      <td>2745</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>12.3206</td>\n",
       "      <td>0.6838</td>\n",
       "      <td>5564</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>30.1976</td>\n",
       "      <td>0.6001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(20, 20)</td>\n",
       "      <td>1971</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>7.9100</td>\n",
       "      <td>0.6342</td>\n",
       "      <td>5066</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>31.4399</td>\n",
       "      <td>0.6068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(20, 50)</td>\n",
       "      <td>1057</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>4.5318</td>\n",
       "      <td>0.6187</td>\n",
       "      <td>2783</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>18.9034</td>\n",
       "      <td>0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(50, 10)</td>\n",
       "      <td>3552</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>17.1623</td>\n",
       "      <td>0.7280</td>\n",
       "      <td>6408</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>32.0783</td>\n",
       "      <td>0.5886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(50, 20)</td>\n",
       "      <td>2317</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>9.4673</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>5165</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>29.0854</td>\n",
       "      <td>0.6033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>1057</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>4.5318</td>\n",
       "      <td>0.6187</td>\n",
       "      <td>2783</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>18.9034</td>\n",
       "      <td>0.5994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_estimators, gamma  train_sig_num  train_ret_mean  train_ret_total  \\\n",
       "0            (10, 10)           2105          0.0043           9.0737   \n",
       "1            (10, 20)           1485          0.0042           6.2007   \n",
       "2            (10, 50)           1004          0.0041           4.0890   \n",
       "3            (20, 10)           2745          0.0045          12.3206   \n",
       "4            (20, 20)           1971          0.0040           7.9100   \n",
       "5            (20, 50)           1057          0.0043           4.5318   \n",
       "6            (50, 10)           3552          0.0048          17.1623   \n",
       "7            (50, 20)           2317          0.0041           9.4673   \n",
       "8            (50, 50)           1057          0.0043           4.5318   \n",
       "\n",
       "   train_profit_rate  test_sig_num  test_ret_mean  test_ret_total  \\\n",
       "0             0.6580          4703         0.0062         28.9818   \n",
       "1             0.6424          4262         0.0069         29.3659   \n",
       "2             0.6225          2956         0.0069         20.5244   \n",
       "3             0.6838          5564         0.0054         30.1976   \n",
       "4             0.6342          5066         0.0062         31.4399   \n",
       "5             0.6187          2783         0.0068         18.9034   \n",
       "6             0.7280          6408         0.0050         32.0783   \n",
       "7             0.6470          5165         0.0056         29.0854   \n",
       "8             0.6187          2783         0.0068         18.9034   \n",
       "\n",
       "   test_profit_rate  \n",
       "0            0.6028  \n",
       "1            0.6138  \n",
       "2            0.6045  \n",
       "3            0.6001  \n",
       "4            0.6068  \n",
       "5            0.5994  \n",
       "6            0.5886  \n",
       "7            0.6033  \n",
       "8            0.5994  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbEval(train_X, train_y, train, test_X, test_y, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5632dfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>bond_ticker</th>\n",
       "      <th>stock_ticker</th>\n",
       "      <th>top1500</th>\n",
       "      <th>CSI300</th>\n",
       "      <th>CSI800</th>\n",
       "      <th>knn10</th>\n",
       "      <th>knn30</th>\n",
       "      <th>knn50</th>\n",
       "      <th>knn100</th>\n",
       "      <th>rf5_0.002</th>\n",
       "      <th>rf5_0.005</th>\n",
       "      <th>rf5_0.01</th>\n",
       "      <th>rf10_0.002</th>\n",
       "      <th>rf10_0.005</th>\n",
       "      <th>rf10_0.01</th>\n",
       "      <th>rf50_0.002</th>\n",
       "      <th>rf50_0.005</th>\n",
       "      <th>rf50_0.01</th>\n",
       "      <th>xgb10_10</th>\n",
       "      <th>xgb10_20</th>\n",
       "      <th>xgb10_50</th>\n",
       "      <th>xgb20_10</th>\n",
       "      <th>xgb20_20</th>\n",
       "      <th>xgb20_50</th>\n",
       "      <th>xgb50_10</th>\n",
       "      <th>xgb50_20</th>\n",
       "      <th>xgb50_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20170104</td>\n",
       "      <td>110030.SH</td>\n",
       "      <td>600185.SH</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20170104</td>\n",
       "      <td>110031.SH</td>\n",
       "      <td>600271.SH</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20170104</td>\n",
       "      <td>110032.SH</td>\n",
       "      <td>600031.SH</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20170104</td>\n",
       "      <td>110033.SH</td>\n",
       "      <td>600755.SH</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20170104</td>\n",
       "      <td>110034.SH</td>\n",
       "      <td>600998.SH</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date bond_ticker stock_ticker  top1500  CSI300  CSI800  knn10  knn30  \\\n",
       "0  20170104   110030.SH    600185.SH    False   False   False      1      0   \n",
       "1  20170104   110031.SH    600271.SH    False    True    True      0      0   \n",
       "2  20170104   110032.SH    600031.SH    False    True    True      0      0   \n",
       "3  20170104   110033.SH    600755.SH     True   False    True      0      0   \n",
       "4  20170104   110034.SH    600998.SH    False   False   False      0      0   \n",
       "\n",
       "   knn50  knn100  rf5_0.002  rf5_0.005  rf5_0.01  rf10_0.002  rf10_0.005  \\\n",
       "0      0       0          0          0         0           0           0   \n",
       "1      0       0          0          0         0           0           0   \n",
       "2      0       0          0          0         0           0           0   \n",
       "3      0       0          0          0         0           0           0   \n",
       "4      0       0          0          0         0           0           0   \n",
       "\n",
       "   rf10_0.01  rf50_0.002  rf50_0.005  rf50_0.01  xgb10_10  xgb10_20  xgb10_50  \\\n",
       "0          0           0           0          0         0         0         0   \n",
       "1          0           0           0          0         0         0         0   \n",
       "2          0           0           0          0         0         0         0   \n",
       "3          0           0           0          0         0         0         0   \n",
       "4          0           0           0          0         0         0         0   \n",
       "\n",
       "   xgb20_10  xgb20_20  xgb20_50  xgb50_10  xgb50_20  xgb50_50  \n",
       "0         0         0         0         0         0         0  \n",
       "1         0         0         0         0         0         0  \n",
       "2         0         0         0         0         0         0  \n",
       "3         0         0         0         0         0         0  \n",
       "4         0         0         0         0         0         0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save ml factors used in backtest\n",
    "cols = ['date', 'bond_ticker', 'stock_ticker', 'top1500', 'CSI300', 'CSI800'] + [\n",
    "    col for col in model_data.columns if col.startswith('knn') or col.startswith('rf') or col.startswith('xgb')]\n",
    "\n",
    "ovnt_ml = model_data[cols].copy()\n",
    "ovnt_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "326ee182",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovnt_ml.to_csv(os.path.join(data_path, 'ovnt_ml.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
